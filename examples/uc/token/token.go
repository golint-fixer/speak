// generated by speak; DO NOT EDIT.

// Package token defines constants representing the lexical tokens of the source
// language.
package token

import "fmt"

// A Token represents a lexical token of the source language.
type Token struct {
	// Start position in the source input.
	Pos int
	// Token type.
	ID ID
	// Token literal.
	Lit []byte
}

// String returns the string represenatation of the token.
func (tok *Token) String() string {
	return fmt.Sprintf("Pos: %d, ID: %s, Lit: %q", tok.Pos, tok.ID, tok.Lit)
}

// ID is the set of lexical tokens of the source language.
type ID int

// None represents a non-existent token ID.
const None ID = 0

// Minimum and maximum token ID for each category of tokens, as specified by the
// language grammar.
const (
	minName  ID = 1
	maxName  ID = 3
	minToken ID = 4
	maxToken ID = 29
	minSkip  ID = 30
	maxSkip  ID = 31
)

// String returns the string represenatation of the token ID.
func (id ID) String() string {
	if int(id) < len(IDs) {
		return IDs[id]
	}
	return fmt.Sprintf("<unknown token ID %d>", int(id))
}

// IsName reports whether the given token ID is represented by a production name
// in the language grammar.
func (id ID) IsName() bool {
	return minName <= id && id <= maxName
}

// IsToken reports whether the given token ID is represented by a token literal
// in the language grammar.
func (id ID) IsToken() bool {
	return minToken <= id && id <= maxToken
}

// IsSkip reports whether the given token ID is part of the ignored set of
// tokens in the language grammar.
func (id ID) IsSkip() bool {
	return minSkip <= id && id <= maxSkip
}

// NTokens specifies the number of unique token IDs recognized by the language
// grammar.
const NTokens = 31

// IDs specifies the string representation of each token ID.
var IDs = [...]string{
	"NONE(0)",
	"name(1, `char_lit`)",
	"name(2, `ident`)",
	"name(3, `int_lit`)",
	"token(4, `!`)",
	"token(5, `!=`)",
	"token(6, `&&`)",
	"token(7, `(`)",
	"token(8, `)`)",
	"token(9, `*`)",
	"token(10, `+`)",
	"token(11, `,`)",
	"token(12, `-`)",
	"token(13, `/`)",
	"token(14, `;`)",
	"token(15, `<`)",
	"token(16, `<=`)",
	"token(17, `=`)",
	"token(18, `==`)",
	"token(19, `>`)",
	"token(20, `>=`)",
	"token(21, `[`)",
	"token(22, `]`)",
	"token(23, `else`)",
	"token(24, `if`)",
	"token(25, `return`)",
	"token(26, `typedef`)",
	"token(27, `while`)",
	"token(28, `{`)",
	"token(29, `}`)",
	"skip(30, `comment`)",
	"skip(31, `whitespace`)",
}
