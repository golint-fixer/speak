// generated by speak; DO NOT EDIT.

// Package token defines constants representing the lexical tokens of the source
// language.
package token

import "fmt"

// A Token represents a lexical token of the source language.
type Token struct {
	// Start position in the source input.
	Pos int
	// Token type.
	ID ID
	// Token literal.
	Lit []byte
}

// String returns the string represenatation of the token.
func (tok *Token) String() string {
	return fmt.Sprintf("Pos: %d, ID: %s, Lit: %q", tok.Pos, tok.ID, tok.Lit)
}

// ID is the set of lexical tokens of the source language.
type ID uint

// String returns the string represenatation of the token ID.
func (id ID) String() string {
	if int(id) < len(IDs) {
		return IDs[id]
	}
	return fmt.Sprintf("<unknown token ID %d>", uint(id))
}

// IDs specifies the string representation of each token ID.
var IDs = [...]string{
	"name(0, `char_lit`)",
	"name(1, `ident`)",
	"name(2, `int_lit`)",
	"token(3, `!`)",
	"token(4, `!=`)",
	"token(5, `&&`)",
	"token(6, `(`)",
	"token(7, `)`)",
	"token(8, `*`)",
	"token(9, `+`)",
	"token(10, `,`)",
	"token(11, `-`)",
	"token(12, `/`)",
	"token(13, `;`)",
	"token(14, `<`)",
	"token(15, `<=`)",
	"token(16, `=`)",
	"token(17, `==`)",
	"token(18, `>`)",
	"token(19, `>=`)",
	"token(20, `[`)",
	"token(21, `]`)",
	"token(22, `else`)",
	"token(23, `if`)",
	"token(24, `return`)",
	"token(25, `typedef`)",
	"token(26, `while`)",
	"token(27, `{`)",
	"token(28, `}`)",
	"skip(29, `comment`)",
	"skip(30, `whitespace`)",
}
